{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Coordinated-Multi-Agent-Imitation-Learning/code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 08:04:58.244177: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-20 08:04:59.303352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-20 08:05:06.956252: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os, sys, math, warnings, copy, time\n",
    "import matplotlib.pyplot as  plt\n",
    "\n",
    "# customized ftns \n",
    "from preprocessing import *\n",
    "from utilities import *\n",
    "from model import *\n",
    "from train import train_all_single_policies\n",
    "# ---------------------------------------------------------\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "# ---------------------------------------------------------\n",
    "# directories\n",
    "main_dir = '../'\n",
    "game_dir = main_dir+'data/'\n",
    "Data = LoadData(main_dir, game_dir)\n",
    "models_path = './models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/0021500463.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# %%time\u001b[39;00m\n\u001b[32m      2\u001b[39m game_id = \u001b[33m'\u001b[39m\u001b[33m0021500463\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m game_data = \u001b[43mData\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m events_df = pd.DataFrame(game_data[\u001b[33m'\u001b[39m\u001b[33mevents\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mraw events shape:\u001b[39m\u001b[33m'\u001b[39m, events_df.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Coordinated-Multi-Agent-Imitation-Learning/code/utilities.py:67\u001b[39m, in \u001b[36mLoadData.load_game\u001b[39m\u001b[34m(self, gameid)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_game\u001b[39m(\u001b[38;5;28mself\u001b[39m, gameid):\n\u001b[32m     66\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''return a dataframe from a game'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgame_dir\u001b[49m\u001b[43m+\u001b[49m\u001b[43mgameid\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Coordinated-Multi-Agent-Imitation-Learning/.venv/lib/python3.12/site-packages/pandas/io/pickle.py:185\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m4    4    9\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m excs_to_catch = (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Coordinated-Multi-Agent-Imitation-Learning/.venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/0021500463.pkl'"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "game_id = '0021500463'\n",
    "game_data = Data.load_game(game_id)\n",
    "events_df = pd.DataFrame(game_data['events'])\n",
    "print('raw events shape:', events_df.shape)\n",
    "home_id = events_df.loc[0].home['teamid']\n",
    "events_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610612741"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.home[0]['teamid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610612761"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.visitor[0]['teamid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some suplementary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # play id to play roles/positions\n",
    "# id_role = id_position(events_df)\n",
    "# check_game_roles_duplicates(id_role)\n",
    "\n",
    "# # its possible that F has similar role as G-f or F-G, we create empty slots to ensure meta order\n",
    "# # ddentify defending and offending runs (this is included in process_moments)\n",
    "# court_index = Data.load_csv('./meta_data/court_index.csv')\n",
    "# court_index = dict(zip(court_index.game_id, court_index.court_position))\n",
    "\n",
    "# # home and visitor ids\n",
    "# homeid = events_df.loc[0].home['teamid']\n",
    "# awayid = events_df.loc[0].visitor['teamid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILTER EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# events_df.loc[3].playbyplay.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# events_df.moments[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_event = 233\n",
    "# P = PlotGame('0021500196', main_dir, game_dir)\n",
    "# for i in range(len(events_df.moments[n_event])):\n",
    "#     P.load_moment2img(game_data, n_event, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as we saw that the playbyplay description of events is not accurate, so for now at least we will not try to filter by events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_non_eleven(events_df, event_length_th=25, verbose=False):\n",
    "    df = events_df.copy()\n",
    "    home_id = df.loc[0]['home']['teamid']\n",
    "    away_id = df.loc[0]['visitor']['teamid']\n",
    "    def remove_non_eleven_(moments, event_length_th=25, verbose=False):\n",
    "        ''' Go through each moment, when encounters balls not present on court,\n",
    "            or less than 10 players, discard these moments and then chunk the following moments \n",
    "            to as another event.\n",
    "\n",
    "            Motivations: balls out of bound or throwing the ball at side line will\n",
    "                probably create a lot noise for the defend trajectory learning model.\n",
    "                We could add the case where players are less than 10 (it could happen),\n",
    "                but this is not allowed in the model and it requres certain input dimension.\n",
    "\n",
    "            moments: A list of moments\n",
    "            event_length_th: The minimum length of an event\n",
    "\n",
    "            segments: A list of events (or, list of moments) e.g. [ms1, ms2] where msi = [m1, m2]\n",
    "        '''\n",
    "\n",
    "        segments = []\n",
    "        segment = []\n",
    "        # looping through each moment\n",
    "        for i in range(len(moments)):\n",
    "            # get moment dimension\n",
    "            moment_dim = len(moments[i][5])\n",
    "            # 1 bball + 10 players\n",
    "            if moment_dim == 11:\n",
    "                segment.append(moments[i])\n",
    "            # less than ten players or basketball is not on the court\n",
    "            else:\n",
    "    #             print('less than 11')\n",
    "                # only grab these satisfy the length threshold\n",
    "                if len(segment) >= event_length_th:\n",
    "                    segments.append(segment)\n",
    "                # reset the segment to empty list\n",
    "                segment = []\n",
    "        # grab the last one\n",
    "        if len(segment) >= event_length_th:\n",
    "            segments.append(segment)\n",
    "        if len(segments) == 0:\n",
    "            if verbose: print('Warning: Zero length event returned')\n",
    "        return segments\n",
    "    # process for each event (row)\n",
    "    df['chunked_moments'] = df.moments.apply(lambda m: remove_non_eleven_(m, event_length_th, verbose))\n",
    "    # in case there's zero length event\n",
    "    df = df[df['chunked_moments'].apply(lambda e: len(e)) != 0]\n",
    "    df['chunked_moments'] = df['chunked_moments'].apply(lambda e: e[0])\n",
    "    return df['chunked_moments'].values, {'home_id': home_id, 'away_id': away_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r, team_ids = remove_non_eleven(events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df1 = pd.DataFrame({'moments': r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunk_shotclock(events_df, event_length_th=25, verbose=False):\n",
    "    df = events_df.copy()\n",
    "    def chunk_shotclock_(moments, event_length_th, verbose):\n",
    "        ''' When encounters ~24secs or game stops, chunk the moment to another event.\n",
    "            shot clock test:\n",
    "            1) c = [20.1, 20, 19, None,18, 12, 9, 7, 23.59, 23.59, 24, 12, 10, None, None, 10]\n",
    "              result = [[20.1, 20, 19], [18, 12, 9, 7], [23.59], [23.59], [24, 12, 10]]\n",
    "            2) c = [20.1, 20, 19, None, None,18, 12, 9, 7, 7, 7, 23.59, 23.59, 24, 12, 10, None, None, 10]\n",
    "              result = [[20.1, 20, 19], [18, 12, 9, 7], [7], [7], [23.59], [23.59], [24, 12, 10]]\n",
    "\n",
    "            Motivations: game flow would make sharp change when there's 24s or \n",
    "            something happened on the court s.t. the shot clock is stopped, thus discard\n",
    "            these special moments and remake the following valid moments to be next event.\n",
    "\n",
    "            moments: A list of moments\n",
    "            event_length_th: The minimum length of an event\n",
    "            verbose: print out exceptions or not\n",
    "\n",
    "            segments: A list of events (or, list of moments) e.g. [ms1, ms2] where msi = [m1, m2] \n",
    "        '''\n",
    "\n",
    "        segments = []\n",
    "        segment = []\n",
    "        # naturally we won't get the last moment, but it should be okay\n",
    "        for i in range(len(moments)-1):\n",
    "            current_shot_clock_i = moments[i][3]\n",
    "            next_shot_clock_i = moments[i+1][3]\n",
    "            # sometimes the shot clock value is None, thus cannot compare\n",
    "            try:\n",
    "                # if the game is still going i.e. sc is decreasing\n",
    "                if next_shot_clock_i < current_shot_clock_i:\n",
    "                    segment.append(moments[i])\n",
    "                # for any reason the game is sstopped or reset\n",
    "                else:\n",
    "                    # not forget the last moment before game reset or stopped\n",
    "                    if current_shot_clock_i < 24.:\n",
    "                        segment.append(moments[i])\n",
    "                    # add length condition\n",
    "                    if len(segment) >= event_length_th:\n",
    "                        segments.append(segment)\n",
    "                    # reset the segment to empty list\n",
    "                    segment = []\n",
    "            # None value\n",
    "            except Exception as e:\n",
    "                if verbose: print(e)\n",
    "                # not forget the last valid moment before None value\n",
    "                if current_shot_clock_i != None:\n",
    "                    segment.append(moments[i])    \n",
    "                if len(segment) >= event_length_th:\n",
    "                    segments.append(segment)\n",
    "                # reset the segment to empty list\n",
    "                segment = []\n",
    "\n",
    "        # grab the last one\n",
    "        if len(segment) >= event_length_th:\n",
    "            segments.append(segment)            \n",
    "        if len(segments) == 0:\n",
    "            if verbose: print('Warning: Zero length event returned')\n",
    "        return segments\n",
    "    \n",
    "    # process for each event (row)\n",
    "    df['chunked_moments'] = df.moments.apply(lambda m: chunk_shotclock_(m, event_length_th, verbose))\n",
    "    # in case there's zero length event\n",
    "    df = df[df['chunked_moments'].apply(lambda e: len(e)) != 0]\n",
    "    df['chunked_moments'] = df['chunked_moments'].apply(lambda e: e[0])\n",
    "    return df['chunked_moments'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = chunk_shotclock(events_df1)\n",
    "events_df2 = pd.DataFrame({'moments': r1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunk_halfcourt(events_df, event_length_th=25, verbose=False):\n",
    "    df = events_df.copy()\n",
    "    def chunk_halfcourt_(moments, event_length_th, verbose):\n",
    "        ''' Discard any plays that are not single sided. When the play switches \n",
    "            court withhin one event, we chunk it to be as another event\n",
    "        '''\n",
    "\n",
    "        # NBA court size 94 by 50 feet\n",
    "        half_court = 94/2. # feet\n",
    "        cleaned = []\n",
    "\n",
    "        # remove any moments where two teams are not playing at either side of the court\n",
    "        for i in moments:\n",
    "            # the x coordinates is on the 3rd or 2 ind of the matrix,\n",
    "            # the first and second is team_id and player_id\n",
    "            team1x = np.array(i[5])[1:6, :][:, 2]    # player data starts from 1, 0 ind is bball\n",
    "            team2x = np.array(i[5])[6:11, :][:, 2]\n",
    "            # if both team are on the left court:\n",
    "            if sum(team1x <= half_court)==5 and sum(team2x <= half_court)==5:\n",
    "                cleaned.append(i)\n",
    "            elif sum(team1x >= half_court)==5 and sum(team2x >= half_court)==5:\n",
    "                cleaned.append(i)\n",
    "\n",
    "        # if teamns playing court changed during same list of moments,\n",
    "        # chunk it to another event\n",
    "        segments = []\n",
    "        segment = []\n",
    "        for i in range(len(cleaned)-1):\n",
    "            current_mean = np.mean(np.array(cleaned[i][5])[:, 2], axis=0)\n",
    "            current_pos = 'R' if current_mean >= half_court else 'L'\n",
    "            next_mean = np.mean(np.array(cleaned[i+1][5])[:, 2], axis=0)\n",
    "            next_pos = 'R' if next_mean >= half_court else 'L'\n",
    "\n",
    "            # the next moment both team are still on same side as current\n",
    "            if next_pos == current_pos:\n",
    "                segment.append(cleaned[i])\n",
    "            else:\n",
    "                if len(segment) >= event_length_th:\n",
    "                    segments.append(segment)\n",
    "                segment = []\n",
    "        # grab the last one\n",
    "        if len(segment) >= event_length_th:\n",
    "            segments.append(segment)            \n",
    "        if len(segments) == 0:\n",
    "            if verbose: print('Warning: Zero length event returned')\n",
    "        return segments\n",
    "    \n",
    "    # process for each event (row)\n",
    "    df['chunked_moments'] = df.moments.apply(lambda m: chunk_halfcourt_(m, event_length_th, verbose))\n",
    "    # in case there's zero length event\n",
    "    df = df[df['chunked_moments'].apply(lambda e: len(e)) != 0]\n",
    "    df['chunked_moments'] = df['chunked_moments'].apply(lambda e: e[0])\n",
    "    return df['chunked_moments'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2 = chunk_halfcourt(events_df2)\n",
    "events_df3 = pd.DataFrame({'moments': r2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# court_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "court_index = pd.read_csv('./meta_data/court_index.csv')\n",
    "court_index = dict(zip(court_index.game_id, court_index.court_position))\n",
    "court_index[int('0021500196')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reorder_teams(events_df, game_id):\n",
    "    df = events_df.copy()\n",
    "    def reorder_teams_(input_moments, game_id):\n",
    "        ''' 1) the matrix always lays as home top and away bot VERIFIED\n",
    "            2) the court index indicate which side the top team (home team) defends VERIFIED\n",
    "\n",
    "            Reorder the team position s.t. the defending team is always the first \n",
    "\n",
    "            input_moments: A list moments\n",
    "            game_id: str of the game id\n",
    "        '''\n",
    "        # now we want to reorder the team position based on meta data\n",
    "        court_index = pd.read_csv('./meta_data/court_index.csv')\n",
    "        court_index = dict(zip(court_index.game_id, court_index.court_position))\n",
    "\n",
    "        full_court = 94.\n",
    "        half_court = full_court/2. # feet\n",
    "        home_defense = court_index[int(game_id)]\n",
    "        moments = copy.deepcopy(input_moments)\n",
    "        for i in range(len(moments)):\n",
    "            home_moment_x = np.array(moments[i][5])[1:6,2]\n",
    "            away_moment_x = np.array(moments[i][5])[6:11,2]\n",
    "            quarter = moments[i][0]\n",
    "            # if the home team's basket is on the left\n",
    "            if home_defense == 0:\n",
    "                # first half game\n",
    "                if quarter <= 2:\n",
    "                    # if the home team is over half court, this means they are doing offense\n",
    "                    # and the away team is defending, so switch the away team to top\n",
    "                    if sum(home_moment_x>=half_court)==5 and sum(away_moment_x>=half_court)==5:\n",
    "                        moments[i][5][1:6], moments[i][5][6:11] = moments[i][5][6:11], moments[i][5][1:6]\n",
    "                        for l in moments[i][5][1:6]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                        for l in moments[i][5][6:11]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                # second half game      \n",
    "                elif quarter > 2: # second half game, 3,4 quarter\n",
    "                    # now the home actually gets switch to the other court\n",
    "                    if sum(home_moment_x<=half_court)==5 and sum(away_moment_x<=half_court)==5:\n",
    "                        moments[i][5][1:6], moments[i][5][6:11] = moments[i][5][6:11], moments[i][5][1:6]\n",
    "                    elif sum(home_moment_x>=half_court)==5 and sum(away_moment_x>=half_court)==5:\n",
    "                        for l in moments[i][5][1:6]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                        for l in moments[i][5][6:11]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                else:\n",
    "                    print('Should not be here, check quarter value')\n",
    "            # if the home team's basket is on the right\n",
    "            elif home_defense == 1:\n",
    "                # first half game\n",
    "                if quarter <= 2:\n",
    "                    # if the home team is over half court, this means they are doing offense\n",
    "                    # and the away team is defending, so switch the away team to top\n",
    "                    if sum(home_moment_x<=half_court)==5 and sum(away_moment_x<=half_court)==5:\n",
    "                        moments[i][5][1:6], moments[i][5][6:11] = moments[i][5][6:11], moments[i][5][1:6]\n",
    "                    elif sum(home_moment_x>=half_court)==5 and sum(away_moment_x>=half_court)==5:\n",
    "                        for l in moments[i][5][1:6]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                        for l in moments[i][5][6:11]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                # second half game      \n",
    "                elif quarter > 2: # second half game, 3,4 quarter\n",
    "                    # now the home actually gets switch to the other court\n",
    "                    if sum(home_moment_x>=half_court)==5 and sum(away_moment_x>=half_court)==5:\n",
    "                        moments[i][5][1:6], moments[i][5][6:11] = moments[i][5][6:11], moments[i][5][1:6]\n",
    "                        for l in moments[i][5][1:6]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                        for l in moments[i][5][6:11]:\n",
    "                            l[2] = full_court - l[2]\n",
    "                else:\n",
    "                    print('Should not be here, check quarter value')\n",
    "        return moments\n",
    "    return [reorder_teams_(m, game_id) for m in df.moments.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r3 = reorder_teams(events_df3, game_id)\n",
    "events_df4 = pd.DataFrame({'moments': r3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_moments(events_df):\n",
    "    df = events_df.copy()\n",
    "    def flatten_moment(moment):\n",
    "        m = np.array(moment[5])\n",
    "        features = np.concatenate((m[1:11, 2:4].reshape(-1),    # x,y of all 10 players \n",
    "                                   m[0][2:5],                   # basketball x,y,z \n",
    "                                   np.array([moment[0]]),       # quarter number \n",
    "                                   np.array([moment[2]]),       # time in seconds left to the end of the period\n",
    "                                   np.array([moment[3]])))      # shot clock \n",
    "        return features\n",
    "    \n",
    "    def get_team_ids(moment):\n",
    "        m = np.array(moment[5])\n",
    "        team_id1 = set(m[1:6, 0])\n",
    "        team_id2 = set(m[6:11, 0])\n",
    "        assert len(team_id1) == len(team_id2) == 1\n",
    "        assert team_id1 != team_id2\n",
    "        return [list(team_id1)[0], list(team_id2)[0]]\n",
    "        \n",
    "        \n",
    "    df['flattened'] = df.moments.apply(lambda ms: [flatten_moment(m) for m in ms])\n",
    "    df['team_ids'] = df.moments.apply(lambda ms: get_team_ids(ms[0])) # just use the first one to determine        \n",
    "    \n",
    "    return df['flattened'].values, df['team_ids'].values\n",
    "\n",
    "r4, team_ids = flatten_moments(events_df4)\n",
    "events_df5 = pd.DataFrame({'moments': r4})   \n",
    "\n",
    "\n",
    "def create_static_features(events_df):\n",
    "    df = events_df.copy()\n",
    "    def create_static_features_(moment):\n",
    "        ''' moment: flatten moment i.e. (25=10*2+3+2,)'''\n",
    "        # distance of each players to the ball\n",
    "        player_xy = moment[:10*2]\n",
    "        b_xy = moment[10*2:10*2+2]\n",
    "        hoop_xy = np.array([3.917, 25])\n",
    "\n",
    "        def disp_(pxy, target):\n",
    "            # dispacement to bball\n",
    "            disp = pxy.reshape(-1, 2) - np.tile(target, (10, 1))\n",
    "            r = np.sqrt(disp[:,0]**2 + disp[:, 1]**2)               # r \n",
    "            cos_theta = disp[:, 0]/r                                # costheta\n",
    "            sin_theta = disp[:, 1]/r                                # sintheta\n",
    "            theta = np.arccos(cos_theta)                            # theta\n",
    "            return np.concatenate((r, cos_theta, sin_theta, theta))\n",
    "        return np.concatenate((moment, disp_(player_xy, b_xy), disp_(player_xy, hoop_xy)))\n",
    "    df['enriched'] = df.moments.apply(lambda ms: np.vstack([create_static_features_(m) for m in ms]))\n",
    "    return df['enriched'].values\n",
    "    \n",
    "r5 = create_static_features(events_df5)\n",
    "events_df6 = pd.DataFrame({'moments': r5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dynamic_features(events_df, fs):\n",
    "    df = events_df.copy()\n",
    "    def create_dynamic_features_(moments, fs):\n",
    "        ''' moments: (moments length, n existing features)'''\n",
    "        pxy = moments[:, :23] # get the players x,y and basketball x,y,z coordinates\n",
    "        next_pxy = np.roll(pxy, -1, axis=0) # get next frame value\n",
    "        vel = ((next_pxy - pxy)/fs)[:-1, :] # the last velocity is not meaningful\n",
    "        # when we combine this back to the original features, we shift one done,\n",
    "        # i.e. [p1, p2, ..., pT] combine [_, p2-p1, ...., pT-pT_1]\n",
    "        # the reason why we shift is that we don't want to leak next position info\n",
    "        return np.column_stack([moments[1:, :], vel])\n",
    "    df['enriched'] = df.moments.apply(lambda ms: create_dynamic_features_(ms, fs))\n",
    "    return df['enriched'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r6 = create_dynamic_features(events_df6, 1/25.)\n",
    "events_df7 = pd.DataFrame({'moments': r6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([1, 2, 3, 4, 5]))\n",
      "(array([1, 2, 3, 4, 5]), array([2, 3, 4, 5, 6]))\n"
     ]
    }
   ],
   "source": [
    "sample = np.arange(6)\n",
    "batchsize1 = 5\n",
    "for i in iterate_minibatches(sample, sample+1, batchsize1, False):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### role alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10*2 (10 players with x,y) + 3(bball x,y,z) + 1(qtr number) + 1(time left in qtr) + 1(sc) + \n",
    "# 10*(4(r,cos,sin,theta)_bball + 4(r, cos, sin, theta)_hoop) + 10*2 (10 players vx, vy) + 3(bball vx,vy,vz)\n",
    "n_fts = 10*2 + 3 + 1 + 1 + 1 + 10*(4+4) + 10*2 + 3\n",
    "n_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hidden_role_learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HSL.defend_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HSL = HiddenStructureLearning(events_df7, libmode='hmmlearn', defend_iter=100, offend_iter=100)\n",
    "t1 = time.time()\n",
    "role_assignments, result1 = HSL.assign_roles(player_inds=HSL.defend_players, n_iter=HSL.defend_iter, mode='euclidean')\n",
    "print('took: {0:.2f}'.format((time.time()-t1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pomegranate import *\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.enable_gpu()\n",
    "utils.is_gpu_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pomegranate.hmm import HiddenMarkovModel\n",
    "\n",
    "h = HiddenStructureLearning(events_df7, libmode='pom')\n",
    "data = h.create_hmm_input(h.defend_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(data[:2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Model = HiddenMarkovModel.from_samples(NormalDistribution, n_components=5, X=data, \n",
    "                                       stop_threshold=1e-3, n_jobs=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = Model.predict_proba(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_game_data_(game_id, events_df, event_threshold, subsample_factor):\n",
    "    # remove non elevens\n",
    "    logging.debug('removing non eleven')\n",
    "    result, _ = remove_non_eleven(events_df, event_threshold)\n",
    "    df = pd.DataFrame({'moments': result})\n",
    "    # chunk based on shot clock, Nones or stopped timer\n",
    "    logging.debug('chunk shotclock')\n",
    "    result = chunk_shotclock(df, event_threshold)\n",
    "    df = pd.DataFrame({'moments': result})\n",
    "    # chunk based on half court and normalize to all half court\n",
    "    logging.debug('chunk half court')\n",
    "    result = chunk_halfcourt(df, event_threshold)\n",
    "    df = pd.DataFrame({'moments': result})\n",
    "    # reorder team matrix s.t. the first five players are always defend side players\n",
    "    logging.debug('reordering team')\n",
    "    result = reorder_teams(df, game_id)\n",
    "    df = pd.DataFrame({'moments': result})\n",
    "\n",
    "    # features \n",
    "    # flatten data\n",
    "    logging.debug('flatten moment')\n",
    "    result, team_ids = flatten_moments(df)\n",
    "    df = pd.DataFrame({'moments': result})  \n",
    "    # static features\n",
    "    logging.debug('add static features')\n",
    "    result = create_static_features(df)\n",
    "    df = pd.DataFrame({'moments': result})\n",
    "    # dynamic features\n",
    "    logging.debug('add velocities')\n",
    "    fs = 1/25.\n",
    "    result = create_dynamic_features(df, fs)\n",
    "    # one hot encoding\n",
    "    logging.debug('add one hot encoding')\n",
    "    OHE = OneHotEncoding()\n",
    "    result = OHE.add_ohs(result, team_ids)\n",
    "    df = pd.DataFrame({'moments': result})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game_data = Data.load_game('0021500024')\n",
    "events_df = pd.DataFrame(game_data['events'])\n",
    "df = process_game_data_('0021500024', events_df, 100, 2)\n",
    "\n",
    "h = HiddenStructureLearning(events_df7, libmode='pom')\n",
    "event = df.moments.values\n",
    "# create X: array-like, shape (n_samples, n_features)\n",
    "plater_fts = [ms[:, h.find_features_ind(player)[1]] for player in h.defend_players for ms in event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# data = h.create_hmm_input(h.defend_players)\n",
    "data = plater_fts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pomegranate import MultivariateGaussianDistribution as MGD\n",
    "Model = HiddenMarkovModel.from_samples(MGD, 2, data, \n",
    "                                       stop_threshold=1e-3, n_jobs=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pomegranate import MultivariateGaussianDistribution as MGD\n",
    "Model = HiddenMarkovModel.from_samples(MGD, 2, data, \n",
    "                                       stop_threshold=1e-3, n_jobs=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1['state_sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['state_sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(result1['state_sequence'][3] == result['state_sequence'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['state_sequence'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_rows = [len(i) > 0 for i in test_seq]\n",
    "# n_cols = [i.shape[1] for i in test_seq]\n",
    "# assert len(set(n_cols)) == 1\n",
    "# assert sum(n_rows) == len(n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from preprocessing import subsample_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_seq[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subsample_sequence(test_seq, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = pd.DataFrame({'A':a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b['B'] = b.A.apply(lambda x: np.array([0]*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b['B'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((3,2))\n",
    "df = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = np.array([2,4,6,70,-1, 9])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = m.reshape(-1, 2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt((b - np.tile(a, (3,1)))[:, 0]**2 + (b - np.tile(a, (3,1)))[:, 1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(b - np.tile(a, (3,1)))[:, 1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(b - np.tile(a, (3,1)))[:, 0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "17**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = HSL.reorder_moment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(role_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df7.moments.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original = copy.deepcopy(events_df7.moments.values)\n",
    "# reordered = copy.deepcopy(events_df7.moments.values)\n",
    "# divider = 0\n",
    "# lengths = [len(m) for m in original]\n",
    "# # iteratve through each moments length\n",
    "# for i in range(len(lengths)):\n",
    "# #     print(i, len(lengths))\n",
    "#     # grab the corresponding moments' reordered roles\n",
    "#     ra_i = role_assignments[divider:divider+lengths[i]]\n",
    "#     # update the next starting index\n",
    "#     divider += lengths[i]\n",
    "#     # iterate through each moment in the current moments\n",
    "#     for j in range(lengths[i]):\n",
    "#         # iterate through each players\n",
    "#         for p in HSL.defend_players:\n",
    "#             # get the current player feature index\n",
    "#             p_ind = HSL.find_features_ind_(p)[0]\n",
    "#             # get the player feature index corresponding to the reordered role\n",
    "#             re_p_ind = HSL.find_features_ind_(ra_i[j][p])[0]\n",
    "#             reordered[i][j][re_p_ind] = original[i][j][p_ind] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OHE = OneHotEncoding()\n",
    "final = [np.column_stack((r[i], np.tile(OHE.encode(team_ids[i]), (len(r[i]), 1)))) for i in range(len(r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmeans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[1]['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "ed = distance.cdist(result[1]['X'], result[1]['cmeans'], 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concated_ms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmeans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(sum((concated_ms[0]-cmeans[0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(sum((concated_ms[0]-cmeans[1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(ed)//5 # number of sequences\n",
    "assert len(ed) % 5 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = ed[np.arange(5)*n]\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) minimize the wrong posterior i.e. 1 - posterior\n",
    "# 2) euclidean distance to the means\n",
    "# 3) adjusted consine similarity to the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defend_X, defend_lengths = create_hmm_input(events_df7, players=list(range(5)))\n",
    "# offend_X, offend_lengths = create_hmm_input(events_df7, players=list(range(5, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defend_model = hmm.GaussianHMM(n_components=5, covariance_type='diag', n_iter=50, verbose=True)#, random_state=42)\n",
    "# defend_model.fit(defend_X, defend_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# offend_model = hmm.GaussianHMM(n_components=5, covariance_type='diag', n_iter=50, verbose=True)#, random_state=42)\n",
    "# offend_model.fit(offend_X, offend_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from hmmlearn import hmm\n",
    "# model = hmm.GaussianHMM(n_components=5, covariance_type='diag', n_iter=50, verbose=True)\n",
    "# model.fit(X, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cmeans = defend_model.means_\n",
    "# covars = defend_model.covars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state_sequence = defend_model.predict(defend_X, defend_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = defend_lengths.reshape(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = state_sequence.reshape(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.reshape(5, -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defend_lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = defend_lengths.reshape(5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l[0,:] == l[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) sumsample should only happen all the way until the end, e.g. if velocity is computed after subsample then the direction of the velocity will result in more errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coordinated-Multi-Agent-Imitation-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
